```{r, eval=TRUE, echo=FALSE}
knitr::opts_chunk$set(
  fig.width=10,
  message=FALSE,
  warning=FALSE,
  fig.path='figure/',
  fig.cap = ""
)
```

Summary of ALM montly reports
=============================

__Scott Chamberlain__
__`r format(Sys.time(), '%d %B, %Y')`__

## Introduction

A file is created at the end of each month. It holds each DOI's published from that month, including article level metrics summed for each DOI for the month. These files make it easy to analyze data for one particular month, or can be summed together to get a picture of PLOS altmtrics over many months (as I do below). 

```{r loadpkgs, echo=FALSE}
# change directory to /data-quality/monthly/
options(stringsAsFactors = FALSE)
# install.packages(c('dplyr','stringr','tidyr'))
# devtools::install_github("ropensci/alm", ref="alerts")
library('dplyr')
library('stringr')
library('alm')
library('ggplot2')
library('tidyr')
library('knitr')
library('scales')
```

```{r readdata, echo=FALSE, cache=TRUE}
dir <- getwd()
setwd("~/Google Drive/ALM Monthly Reports/PLOS")
files <- list.files(".", pattern = ".csv")
read_file <- function(x){
  tmp <- read.csv(x, header = TRUE, sep = ",", stringsAsFactors=FALSE)
  tmp$datafrom <- as.Date(str_extract(x, "[0-9]{4}-[0-9]{2}-[0-9]{2}"), "%Y-%m-%d")
  tmp
  }
dat <- lapply(files, read_file)
alldat <- rbind_all(dat)
dat2 <- tbl_df(alldat)
setwd(dir)
```

```{r cleandata, echo=FALSE, cache=TRUE}
# new column with date for each row, drop other pub date columns
# and move title to end for easier viewing
dat2 <- dat2 %>%
   mutate(pubdate = published[1], title2 = title) %>%
   select(-published, -publication_date, -title)

# remove negative numbers in facebook
dat2 <- dat2 %>%
   filter(facebook >= 0)

# remove annotation DOIs - NOTE: if you want these, don't run this next few lines of code
annot <- dat2 %>% filter(grepl('annotation', doi)) %>% select(doi)
dat2 <- dat2 %>% 
   filter(!doi %in% annot$doi)
```

## Coverage

```{r echo=FALSE}
dats <- dat2 %>% select(datafrom) %>% distinct(datafrom) %>% data.frame %>% .[,"datafrom"]
mos <- unname(vapply(as.character(dats), function(x) paste0(strsplit(x, "-")[[1]][1:2], collapse = "-"), ""))
domos <- function(yr){
  paste0(yr, '(', paste0(vapply(Filter(function(x) grepl(yr, x), mos), function(y) strsplit(y, "-")[[1]][[2]], ""), collapse = ", "), ')')
}
yrs <- unique(unname(vapply(as.character(dats), function(x) strsplit(x, "-")[[1]][[1]], "")))
mos2 <- paste0(lapply(yrs, domos), collapse = ", ")
```

The monthly data covers:

* `r n_distinct(dat2$datafrom)` months 
* Data from: `r mos2`
* `r n_distinct(dat2$doi)` DOIs
* `r NCOL(dat2 %>% select(-doi, -datafrom, -pubdate, -title2))` article-level metrics variables

```{r echo=FALSE}
dates <- sort(unique(dat2$datafrom))
```

## Summary statistics

Totals of metrics for `r paste0(strsplit(as.character(dates[12]), "-")[[1]][1:2], collapse="-")`, across all DOIs. Newer monthly files are missing some data. Sources are dropped below that have no data, or have a sum or mean of zero.

```{r echo=FALSE}
# get just last months data
dat3 <- dat2 %>% filter(datafrom == dates[12]) %>% select(-doi, -datafrom, -pubdate, -title2)
```

```{r coverage, echo=FALSE}
sum_nona <- function() sum(as.numeric(.), na.rm = TRUE)
sumfxn <- function(x){
  tt <- x %>% data.frame
  df <- plyr::ldply(tt)
  df$`V1` <- round(df$`V1`, 0)
  names(df) <- c('source','var')
  df %>% filter(!is.na(var), var != 0)
}
myplot <- function(){
  list(
    geom_bar(stat = "identity", width = 0.5, fill = 'blue'),
    theme_grey(base_size = 14),
    scale_y_log10(expand = c(0, 0)),
    coord_flip(),
    labs(x="Source")
  )
}
```

__Sum__

```{r sumall, echo=FALSE}
dat3 %>%
  summarise_each(funs(sum(as.numeric(.), na.rm = TRUE))) %>%
  sumfxn %>%
  ggplot(aes(reorder(source, var), var)) + myplot()
```

__Mean__

```{r meanall, echo=FALSE}
dat3 %>%
  summarise_each(funs(mean(as.numeric(.), na.rm = TRUE))) %>%
  sumfxn %>%
  ggplot(aes(reorder(source, var), var)) + myplot()
```

Overview of some altmetrics through time

```{r stats, echo=FALSE}
# dat2 %>%
#   select(doi, twitter, datafrom, pubdate) %>%
#   group_by(datafrom) %>%
#   summarise(val_mean = mean(twitter, na.rm = TRUE)) %>%  
#   ggplot(aes(datafrom, val_mean)) + geom_line() + theme_grey(base_size = 14) 

dat2 %>%
  select(datafrom, crossref, scopus, twitter, counter_html, pmc_html, facebook, mendeley, wikipedia, f1000, figshare, reddit, datacite) %>%
  group_by(datafrom) %>%
  summarise_each(funs(mean(., na.rm = TRUE))) %>%  
  gather(metric, value, -datafrom) %>%
  ggplot(aes(datafrom, value)) + 
    geom_line() + 
    theme_grey(base_size = 14) + 
    facet_wrap(~ metric, scales = "free") +
    scale_x_date(breaks = date_breaks("7 months"), labels = date_format("%m/%y")) +
    labs(x = "Date", y = "")
```
