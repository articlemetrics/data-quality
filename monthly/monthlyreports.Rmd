data-quality code
========================================================

## Install packages 

If the below packages are not installed already, then load package

```{r}
options(stringsAsFactors = FALSE)
# install.packages(c('dplyr','stringr','tidyr'))
# devtools::install_github("ropensci/alm", ref="alerts")
library('dplyr')
library('stringr')
library('alm')
library('ggplot2')
library('tidyr')
```

## Read in data

PLOS folks, Monthly reports are in a Google Drive folder, talk to Martin if you want access

```{r cache=TRUE}
dir <- getwd()
setwd("~/Google Drive/ALM Monthly Reports/")
files <- list.files(".", pattern = ".csv")
read_file <- function(x){
  tmp <- read.csv(x, header = TRUE, sep = ",", stringsAsFactors=FALSE)
  tmp$datafrom <- as.Date(str_extract(x, "[0-9]{4}-[0-9]{2}-[0-9]{2}"), "%Y-%m-%d")
  tmp
  }
dat <- lapply(files, read_file)
alldat <- rbind_all(dat)
(dat2 <- tbl_df(alldat))
setwd(dir)
```

## Data cleaning

```{r cache=TRUE}
# new column with date for each row, drop other pub date columns
# and move title to end for easier viewing
(dat2 <- dat2 %>%
   mutate(pubdate = published[1], title2 = title) %>%
   select(-published, -publication_date, -title))

# remove negative numbers in facebook
(dat2 <- dat2 %>%
   filter(facebook >= 0))

# remove annotation DOIs - NOTE: if you want these, don't run this next few lines of code
annot <- dat2 %>% filter(grepl('annotation', doi)) %>% select(doi)
(dat2 <- dat2 %>% 
   filter(!doi %in% annot$doi))
```

## Through time

Compare each metric separately through time for the same DOIs

### Citeulike data

```{r}
# get dois that have a change in their value of at least n = 10 (modify)  
citeu_dois <- dat2 %>% 
  select(doi, datafrom, citeulike) %>% 
  group_by(doi) %>% 
  summarise(
    diff = max(citeulike) - min(citeulike)
    ) %>% 
  filter(diff > 10) %>% 
  select(doi)

# Visualize data
dat2 %>% 
  select(doi, datafrom, citeulike) %>% 
  filter(doi %in% citeu_dois$doi) %>% 
  ggplot(aes(datafrom, citeulike, group=doi)) + geom_line()
```

### Mendeley data

```{r}
# get dois that have a change in their value of at least n = 10 (modify)
mendeley_dois <-  dat2 %>% 
  select(doi, datafrom, mendeley) %>%
  group_by(doi) %>% 
  summarise(
    diff = max(mendeley, na.rm = TRUE) - min(mendeley, na.rm = TRUE)
    ) %>% 
  filter(diff > 90) %>%
  select(doi)

# Visualize data
dat2 %>%
  select(doi, datafrom, mendeley) %>%
  filter(doi %in% mendeley_dois$doi) %>% 
  ggplot(aes(datafrom, mendeley, group=doi)) + geom_line()

# Visualize data - without outliers
outliers <- unique(dat2 %>% filter(mendeley > 5000) %>% select(doi))$doi
dat2 %>%
  select(doi, datafrom, mendeley) %>%
  filter(doi %in% mendeley_dois$doi, !doi %in% outliers) %>% 
  ggplot(aes(datafrom, mendeley, group=doi)) + geom_line()
```

## Across metrics

### Counter: html vs. pdf views

Compare different metrics across the same DOIs in one time slice

```{r cache=TRUE}
# remove last three dates as they don't have counter_pdf or counter_html data
norecent_counter <- dat2 %>% 
  select(doi, datafrom, contains('counter')) %>% 
  filter(!as.character(datafrom) %in% c('2014-06-10','2014-07-10',"2014-08-10","2014-09-10"))
```


```{r}
norecent_counter %>% 
  ggplot(aes(log10(counter_html+1), log10(counter_pdf+1))) + geom_point() + facet_wrap(~ datafrom)
```

Do slopes through time differ?

```{r}
# remove last three dates as they don't have counter_pdf or counter_html data
# calculate slopes, define function to get slope and confidence interval first
get_coef <- function(x){
  tmp <- lm(counter_pdf ~ counter_html, data = x)
  df <- data.frame(datafrom=x$datafrom[1], slope=coefficients(tmp)[['counter_html']], t(confint(tmp)[2,]))
  names(df)[3:4] <- c('low','high')
  df
}

res <- norecent_counter %>% 
  group_by(datafrom) %>%
  do(out = get_coef(.))
df <- res$out %>% rbind_all

df %>%
  ggplot(aes(datafrom, slope)) + 
  geom_point(aes(size=4)) + 
  theme_grey(20) + 
  theme(legend.position="none") + 
  labs(y="Slope of html to pdf views\n")
```
