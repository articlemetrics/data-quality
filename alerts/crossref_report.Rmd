Crossref Report
========================================================

```{r eval=TRUE, echo=FALSE}
knitr::opts_chunk$set(
  fig.width=10
)
```

### Date 

Compiled on `r Sys.time()`

### Setup

> change directory to /data-quality/alerts/

```{r child='alertssetup.Rmd'}
```

```{r child='alertssetup.Rmd', eval=FALSE}
knitr::purl("alertssetup.Rmd")
source("alertssetup.R")
unlink("alertssetup.R")
```

### Set up variables

```{r variables}
url <- "http://det.labs.crossref.org/api/v4/alerts"
user <- getOption('almv4_crossref_user')
pwd <- getOption('almv4_crossref_pwd')
cr_v5_key <- getOption('crossrefalmkey')
```

### Get all data

```{r getdata, cache=TRUE}
meta <- alm_alerts(url = url, user = user, pwd = pwd)$meta
res <- lapply(1:meta$total_pages, function(x) alm_alerts(page=x, url=url, user=user, pwd=pwd))
(resdf <- do.call(rbind, lapply(res, "[[", "data")) %>% 
   tbl_df %>% 
   select(id, level, class_name, article, status, source, create_date, target_url))
```

### Visual exploration of alerts

#### type of alerts

```{r alerttypes}
library(ggplot2)
resdf %>%
  group_by(class_name) %>%
  summarise(number = length(class_name)) %>%
  ggplot(aes(reorder(class_name, number), number)) +
    geom_histogram(stat = "identity") + 
    coord_flip() +
    theme_grey(base_size = 20) +
    labs(x = "Alert", y = "No. Articles")
```

#### alerts by source

By source alone

> NOTE: the NA's are not mistakes, but what is given as the source

```{r bysource}
resdf %>%
  group_by(source) %>%
  summarise(number = length(source)) %>%
  ggplot(aes(reorder(source, number), number)) +
    geom_histogram(stat = "identity") + 
    coord_flip() +
    theme_grey(base_size = 20) +
    labs(x = "Source", y = "No. Articles")
```

source X alert class

```{r sourcebyclass}
resdf %>%
  group_by(source, class_name) %>%
  summarise(number = length(source)) %>%
  ggplot(aes(reorder(class_name, number), number, fill=source)) +
    geom_histogram(stat = "identity") + 
    coord_flip() +
    theme_grey(base_size = 20) +
    labs(x = "Source", y = "No. Articles") +
    theme(legend.position = "top")
```

Dig into `Net::HTTPForbidden`

```{r prefixes}
library('httr')
library('jsonlite')
res <- GET('http://det.labs.crossref.org//api/v5/publishers', query=list(api_key=cr_v5_key))
prefixes <- fromJSON(content(res, "text"))$data[,c('name','prefixes')]
pre <- prefixes$prefixes
names(pre) <- prefixes$name
```

Define functions

```{r definefxns}
splitdoi <- function(x) strsplit(x, "/")[[1]][[1]]
match_publisher <- function(x, y){
  names(y[ sapply(y, function(z) x %in% z) ])
}
```

Manipulate data

```{r manipulate}
# subset data
dat <- resdf %>%
  filter(class_name == "Net::HTTPForbidden") %>%
  mutate(prefix = splitdoi(article)) %>%
  select(id, level, class_name, article, prefix, status, source, create_date, target_url)

# get publishers
pubs <- dat %>%
  rowwise %>%
  do( publisher = match_publisher(.$prefix, pre) )

# join the two data.frame's
alldf <- tbl_df(cbind(dat, pubs))
alldf$publisher <- as.character(alldf$publisher)
unique(alldf$publisher)
```

> Note: How all these `Net::HTTPForbidden` erors are 403 errors, and all from Wiley, trying to get Wikipedia data source

The only alert class with article IDs is `Net::HTTPForbidden`.
