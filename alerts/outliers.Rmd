Workflow for detecting and exploring just outliers
========================================================

### Date 

Compiled on `r Sys.time()`

### Setup

> change directory to /data-quality/alerts/

```{r child='alertssetup.Rmd'}
```

```{r child='alertssetup.Rmd', eval=FALSE}
knitr::purl("alertssetup.Rmd")
source("alertssetup.R")
unlink("alertssetup.R")
```

### Get alerts data by alert class

#### get data cached for three impt alert classes

```{r eval=FALSE}
classes <- c('HtmlRatioTooHighError','EventCountDecreasingError','EventCountIncreasingTooFastError')
res <- lapply(classes, alerts_by_class, limit=1000)
(resdf <- tbl_df(rbind_all(res)))
```


#### By class, change class_name var at top

```{r}
class_name = 'HtmlRatioTooHighError'
```

Get data

```{r}
(res <- alerts_by_class(class_name, limit=2000))
# remove bad data
res <- res %>%
  filter(!is.na(article))
```

Extract top N articles, get DOIs

```{r}
num_get <- 10
toinspect <- res[1:num_get,] %>% select(-class)
(dois <- toinspect$article)
```

Browse to an article

```{r eval=FALSE}
browseURL(sprintf("http://alm.plos.org/articles/info:doi/%s", res$article[2]))
```


Get ALM events data and merge alerts data to it

```{r}
alldf <- add_events_data(toinspect, dois)
```

ggplot elements to reuse

```{r}
gg <- function(){
  list(geom_line(size = 2, alpha = 0.6),
       geom_vline(aes(xintercept=as.numeric(create_date)), linetype="longdash"),
       ggtitle("HtmlRatioTooHighError - Top ten highest HTML/PDF ratio articles\n"),
       facet_wrap(~ article, ncol = 2, scales = "free"),
       labs(y="", x=""),
       theme_grey(base_size = 14))
}
```

The distribution of html/pdf ratios

```{r ratio_dist}
res %>%
  ggplot(aes(x=val)) + geom_histogram()
```


Plot html and pdf views, just top `r num_get`

```{r fig.width=10}
alldf %>%
  select(-year, -month, -id, -val, -source, -xml_views, -ratio) %>%
  gather(metric, value, -article, -date, -create_date) %>% 
  ggplot(aes(date, value, color=metric)) + gg()
```

The HTML/PDF ratio, just top `r num_get`

```{r fig.width=10}
alldf %>%
  select(-year, -month, -id, -val, -source, -xml_views, -html_views, -pdf_views) %>%
  ggplot(aes(date, ratio)) + gg()
```

All ratio lines together

```{r fig.width=10}
(alldf_alldois <- add_events_data(res, res$article))

alldf_alldois %>%
  select(article, date, create_date, ratio) %>%
  ggplot(aes(date, log10(ratio), group=article)) + 
    geom_line() +
    labs(y="", x="") +
    theme_grey(base_size = 14)
```

Dig in to particular DOIs. This is rather free-form, depends on the metric of interest.

```{r eval=FALSE}
doi1 <- '10.1371/journal.pbio.0040066'
alm_events(doi1, source = "facebook")
alm_ids(doi1, info = "detail")
```

Are the high value offender DOIs associated with other alm metrics, like social media metrics

```{r fig.width=10, eval=FALSE}
dat <- alm_ids(res$article, source = c("facebook","twitter","mendeley","reddit","scopus","wikipedia"))
datdf <- rbind_all(dat$data)
datdf$article <- rep(res$article, each = 6)
datdf <- inner_join(datdf, res %>% filter(article %in% res$article) %>% select(article, val) )

datdf %>% 
  ggplot(aes(x=val, y=total)) + 
    geom_point(aes(size=2)) +
    facet_wrap(~ .id, scales='free') +
    labs(y="", x="") +
    theme_grey(base_size = 18) +
    theme(legend.position="none")
```


Detect spikes/patterns in signals through time

```{r, eval=FALSE}
'not done yet...'
```

> based on the above work, identify which articles are deserving of further inspection/flagging - perhaps need to look at log files for IP addresses, etc.
